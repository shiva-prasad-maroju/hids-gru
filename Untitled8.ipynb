{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNdNUr70Zeu5KT+5CcKufKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiva-prasad-maroju/hids-gru/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9OxWFx7lbsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2e364c-5145-4415-d056-cd660022b989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack_Data_Master  Training_Data_Master  Validation_Data_Master\n"
          ]
        }
      ],
      "source": [
        "!unzip -q ADFA-LD.zip\n",
        "!ls ADFA-LD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "DATASET_ROOT = \"/content/ADFA-LD\"\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Training (benign)\n",
        "for fname in os.listdir(f\"{DATASET_ROOT}/Training_Data_Master\"):\n",
        "    if fname.endswith(\".txt\"):\n",
        "        with open(f\"{DATASET_ROOT}/Training_Data_Master/{fname}\") as f:\n",
        "            X_train.append(list(map(int, f.read().split())))\n",
        "\n",
        "# Validation benign\n",
        "for fname in os.listdir(f\"{DATASET_ROOT}/Validation_Data_Master\"):\n",
        "    if fname.endswith(\".txt\"):\n",
        "        with open(f\"{DATASET_ROOT}/Validation_Data_Master/{fname}\") as f:\n",
        "            X_test.append(list(map(int, f.read().split())))\n",
        "            y_test.append(0)\n",
        "\n",
        "# Attacks (nested)\n",
        "for atk in os.listdir(f\"{DATASET_ROOT}/Attack_Data_Master\"):\n",
        "    atk_dir = f\"{DATASET_ROOT}/Attack_Data_Master/{atk}\"\n",
        "    if not os.path.isdir(atk_dir):\n",
        "        continue\n",
        "    for fname in os.listdir(atk_dir):\n",
        "        if fname.endswith(\".txt\"):\n",
        "            with open(f\"{atk_dir}/{fname}\") as f:\n",
        "                X_test.append(list(map(int, f.read().split())))\n",
        "                y_test.append(1)\n",
        "\n",
        "print(\"Train:\", len(X_train))\n",
        "print(\"Test:\", Counter(y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5JHdi5bmFav",
        "outputId": "c005f305-5010-4668-d5be-fcfe21530af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 833\n",
            "Test: Counter({0: 4372, 1: 746})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3JZnAscmQvJ",
        "outputId": "2f3e1421-1209-4915-8e7f-6bbae4bd4824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "tWKfctD_m0GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = \"/content/ADFA-LD\"\n",
        "\n",
        "X_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "# Training (benign)\n",
        "for f in os.listdir(f\"{DATASET_ROOT}/Training_Data_Master\"):\n",
        "    if f.endswith(\".txt\"):\n",
        "        with open(f\"{DATASET_ROOT}/Training_Data_Master/{f}\") as fh:\n",
        "            X_train.append(list(map(int, fh.read().split())))\n",
        "\n",
        "# Validation benign\n",
        "for f in os.listdir(f\"{DATASET_ROOT}/Validation_Data_Master\"):\n",
        "    if f.endswith(\".txt\"):\n",
        "        with open(f\"{DATASET_ROOT}/Validation_Data_Master/{f}\") as fh:\n",
        "            X_test.append(list(map(int, fh.read().split())))\n",
        "            y_test.append(0)\n",
        "\n",
        "# Attacks (nested)\n",
        "for atk in os.listdir(f\"{DATASET_ROOT}/Attack_Data_Master\"):\n",
        "    atk_dir = f\"{DATASET_ROOT}/Attack_Data_Master/{atk}\"\n",
        "    if not os.path.isdir(atk_dir):\n",
        "        continue\n",
        "    for f in os.listdir(atk_dir):\n",
        "        if f.endswith(\".txt\"):\n",
        "            with open(f\"{atk_dir}/{f}\") as fh:\n",
        "                X_test.append(list(map(int, fh.read().split())))\n",
        "                y_test.append(1)\n",
        "\n",
        "print(\"Train:\", len(X_train))\n",
        "print(\"Test:\", Counter(y_test))\n",
        "X_train_raw = X_train\n",
        "X_test_raw = X_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw3TPjC6m5Zm",
        "outputId": "64aeb382-4f3a-40d7-b4d5-cd6faaee9020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 833\n",
            "Test: Counter({0: 4372, 1: 746})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 1300\n",
        "\n",
        "def pad_np(seqs, maxlen):\n",
        "    arr = np.zeros((len(seqs), maxlen), dtype=np.int32)\n",
        "    for i, s in enumerate(seqs):\n",
        "        s = s[:maxlen]\n",
        "        arr[i, :len(s)] = s\n",
        "    return arr\n",
        "\n",
        "X_train = torch.tensor(pad_np(X_train, MAX_LEN), dtype=torch.long)\n",
        "X_test  = torch.tensor(pad_np(X_test, MAX_LEN), dtype=torch.long)\n",
        "y_test  = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "print(X_train.shape, X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYcvVw-am9YR",
        "outputId": "acd16bb7-464d-41ee-c154-14d2ffec5f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([833, 1300]) torch.Size([5118, 1300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRULanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=64, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embed(x)\n",
        "        h, _ = self.gru(emb)\n",
        "        return self.out(h)\n"
      ],
      "metadata": {
        "id": "M3zpTEnGnAZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n"
      ],
      "metadata": {
        "id": "uqzZv45YpWIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = int(max(X_train.max(), X_test.max())) + 1\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = GRULanguageModel(VOCAB_SIZE).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "loader = DataLoader(TensorDataset(X_train), batch_size=32, shuffle=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for (x,) in loader:\n",
        "        x = x.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x[:, :-1])       # predict next token\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, VOCAB_SIZE),\n",
        "            x[:, 1:].reshape(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    print(f\"Epoch {epoch+1} | Loss {total/len(loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJFePrXinDO1",
        "outputId": "1a4b7e31-4406-44a1-8796-a9a96454c623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss 4.5448\n",
            "Epoch 2 | Loss 2.5587\n",
            "Epoch 3 | Loss 2.1149\n",
            "Epoch 4 | Loss 1.9077\n",
            "Epoch 5 | Loss 1.7583\n",
            "Epoch 6 | Loss 1.6629\n",
            "Epoch 7 | Loss 1.6058\n",
            "Epoch 8 | Loss 1.5255\n",
            "Epoch 9 | Loss 1.4631\n",
            "Epoch 10 | Loss 1.4412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_nll(model, X, batch_size=32):\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    loader = DataLoader(TensorDataset(X), batch_size=batch_size)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (x,) in loader:\n",
        "            x = x.to(device)\n",
        "            logits = model(x[:, :-1])\n",
        "\n",
        "            loss = nn.functional.cross_entropy(\n",
        "                logits.reshape(-1, VOCAB_SIZE),\n",
        "                x[:, 1:].reshape(-1),\n",
        "                ignore_index=0,\n",
        "                reduction=\"none\"\n",
        "            )\n",
        "\n",
        "            seq_loss = loss.view(x.size(0), -1).mean(dim=1)\n",
        "            scores.append(seq_loss.cpu())\n",
        "\n",
        "    return torch.cat(scores)\n"
      ],
      "metadata": {
        "id": "-VSR95HMnGJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "train_scores = sequence_nll(model, X_train)\n",
        "test_scores  = sequence_nll(model, X_test)\n",
        "\n",
        "# Calculate preds for a chosen k (e.g., k=2.0), which was the last value used in the previous cell.\n",
        "k = 2.0\n",
        "thr = train_scores.mean() + k * train_scores.std()\n",
        "preds = (test_scores > thr).long()\n",
        "\n",
        "print(f\"Metrics for k={k}:\")\n",
        "print(confusion_matrix(y_test.cpu(), preds.cpu()))\n",
        "print(classification_report(y_test.cpu(), preds.cpu()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GS6kh85tnNxm",
        "outputId": "79491f6a-7a51-4ec6-92a6-ff6209a61865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for k=2.0:\n",
            "[[3934  438]\n",
            " [ 591  155]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      4372\n",
            "           1       0.26      0.21      0.23       746\n",
            "\n",
            "    accuracy                           0.80      5118\n",
            "   macro avg       0.57      0.55      0.56      5118\n",
            "weighted avg       0.78      0.80      0.79      5118\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_scores = sequence_nll(model, X_train)\n",
        "test_scores  = sequence_nll(model, X_test)\n",
        "\n",
        "for k in [0.5, 1.0, 1.5, 2.0]:\n",
        "    thr = train_scores.mean() + k * train_scores.std()\n",
        "    preds = (test_scores > thr).long()\n",
        "\n",
        "    from sklearn.metrics import recall_score, precision_score\n",
        "    print(\n",
        "        f\"k={k} | recall={recall_score(y_test, preds):.3f} | \"\n",
        "        f\"precision={precision_score(y_test, preds):.3f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkmY8z9Xn6Ty",
        "outputId": "b1d760ed-f0af-4590-ae45-f28a1e252d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=0.5 | recall=0.410 | precision=0.223\n",
            "k=1.0 | recall=0.328 | precision=0.240\n",
            "k=1.5 | recall=0.263 | precision=0.245\n",
            "k=2.0 | recall=0.208 | precision=0.261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pad_np(seqs, maxlen):\n",
        "    arr = np.zeros((len(seqs), maxlen), dtype=np.int32)\n",
        "    for i, s in enumerate(seqs):\n",
        "        s = s[:maxlen]\n",
        "        arr[i, :len(s)] = s\n",
        "    return arr\n"
      ],
      "metadata": {
        "id": "VcsHuXJ6owMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def create_sliding_windows(seq, window, stride):\n",
        "    # Helper function to generate sliding windows from a single sequence\n",
        "    windows = []\n",
        "    for i in range(0, len(seq) - window + 1, stride):\n",
        "        windows.append(seq[i:i + window])\n",
        "    return windows\n",
        "\n",
        "def sliding_window_nll(\n",
        "    model,\n",
        "    sequences,          # list of raw syscall sequences\n",
        "    window=80,\n",
        "    stride=40,\n",
        "    batch_size=64\n",
        "):\n",
        "    model.eval()\n",
        "    scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq in sequences:\n",
        "            windows = create_sliding_windows(seq, window, stride)\n",
        "\n",
        "            # very short sequences\n",
        "            if len(windows) == 0:\n",
        "                scores.append(0.0)\n",
        "                continue\n",
        "\n",
        "            # pad windows\n",
        "            w = torch.tensor(\n",
        "                pad_np(windows, window),\n",
        "                dtype=torch.long\n",
        "            ).to(device)\n",
        "\n",
        "            # language model: predict next syscall\n",
        "            logits = model(w[:, :-1])\n",
        "\n",
        "            loss = F.cross_entropy(\n",
        "                logits.reshape(-1, VOCAB_SIZE),\n",
        "                w[:, 1:].reshape(-1),\n",
        "                ignore_index=0,\n",
        "                reduction=\"none\"\n",
        "            )\n",
        "\n",
        "            # mean NLL per window\n",
        "            window_nll = loss.view(w.size(0), -1).mean(dim=1)\n",
        "\n",
        "            # IMPORTANT: max window = anomaly score\n",
        "            scores.append(window_nll.max().item())\n",
        "\n",
        "    return np.array(scores)"
      ],
      "metadata": {
        "id": "y9T6KWzcDpAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_raw, X_test_raw = original Python lists (before padding)\n",
        "\n",
        "train_scores = sliding_window_nll(\n",
        "    model,\n",
        "    X_train_raw,\n",
        "    window=80,\n",
        "    stride=40\n",
        ")\n",
        "\n",
        "test_scores = sliding_window_nll(\n",
        "    model,\n",
        "    X_test_raw,\n",
        "    window=80,\n",
        "    stride=40\n",
        ")\n"
      ],
      "metadata": {
        "id": "QxCQKJukEdN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score\n",
        "\n",
        "y_true = y_test.cpu().numpy()\n",
        "\n",
        "for k in [0.5, 1.0, 1.5]:\n",
        "    thr = train_scores.mean() + k * train_scores.std()\n",
        "    preds = (test_scores > thr).astype(int)\n",
        "\n",
        "    print(\n",
        "        f\"k={k} | \"\n",
        "        f\"recall={recall_score(y_true, preds):.3f} | \"\n",
        "        f\"precision={precision_score(y_true, preds):.3f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ2ePESUEg-G",
        "outputId": "e7326ffb-4efe-406c-ff81-4215049d6a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=0.5 | recall=0.562 | precision=0.243\n",
            "k=1.0 | recall=0.466 | precision=0.269\n",
            "k=1.5 | recall=0.340 | precision=0.299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WpQKlTGKG47X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}